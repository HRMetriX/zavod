import os
import json
import time
import random
import feedparser
from datetime import datetime, timedelta
import requests
from openai import OpenAI
import traceback
from huggingface_hub import InferenceClient


# === CONFIG ===
TELEGRAM_BOT_TOKEN = os.environ["TELEGRAM_BOT_TOKEN"]
HF_TOKEN = os.environ["HF_TOKEN"]
FB_API_KEY = os.environ["FUSIONBRAIN_API_KEY"]
GIST_TOKEN = os.environ["GIST_TOKEN"]
CHANNEL = os.environ.get("TELEGRAM_CHANNEL", "@notreviews")

RSS_SOURCES = [
    "https://ria.ru/export/rss2/archive/index.xml",
    "https://tass.ru/rss/v2.xml",
    "https://lenta.ru/rss/",
]

# === GIST STATE MANAGEMENT ===
GIST_ID = "5944017a021bcea90b63cf408a0324e5"

def load_seen():
    url = f"https://api.github.com/gists/{GIST_ID}"
    headers = {"Authorization": f"token {GIST_TOKEN}"}
    try:
        resp = requests.get(url, headers=headers, timeout=10)
        if resp.status_code == 200:
            files = resp.json().get("files", {})
            if "seen.json" in files:
                content = files["seen.json"].get("content", "[]")
                return set(json.loads(content))
        return set()
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ seen.json –∏–∑ Gist: {e}")
        return set()

def save_seen(seen_set):
    url = f"https://api.github.com/gists/{GIST_ID}"
    headers = {"Authorization": f"token {GIST_TOKEN}"}
    payload = {
        "files": {
            "seen.json": {
                "content": json.dumps(list(seen_set), ensure_ascii=False, indent=2)
            }
        }
    }
    try:
        requests.patch(url, headers=headers, json=payload, timeout=10)
        print("‚úÖ seen.json –æ–±–Ω–æ–≤–ª—ë–Ω –≤ Gist")
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ Gist: {e}")

# === NEWS PARSING ===
def fetch_political_news(hours=1):
    keywords = ["–ü—É—Ç–∏–Ω", "–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç", "–°–æ–≤–±–µ–∑", "–ú–∏–Ω–æ–±–æ—Ä–æ–Ω—ã", "–õ–∞–≤—Ä–æ–≤", "–®–æ–π–≥—É", "–Ω–∞–∑–Ω–∞—á", "—É–∫–∞–∑", "–°–∞–Ω—á–∏–∫", "–ë—É–ª—ã–≥–∞", "–†–æ—Å—Å–∏—è", "–ø–æ–ª–∏—Ç–∏–∫", "–°–∏", "–ó–µ–ª–µ–Ω—Å–∫", "–ë–∞–π–¥–µ–Ω", "–¢—Ä–∞–º–ø"]
    fresh = []
    cutoff = datetime.now() - timedelta(hours=hours)

    for url in RSS_SOURCES:
        try:
            feed = feedparser.parse(url)
            for entry in feed.entries:
                pub = datetime(*entry.published_parsed[:6])
                if pub < cutoff:
                    continue
                title = entry.title
                summary = entry.get("summary", "")
                if title in seen_titles:
                    continue
                if any(kw in title or kw in summary for kw in keywords):
                    fresh.append({
                        "title": title,
                        "summary": summary[:300],
                        "link": entry.link
                    })
                    seen_titles.add(title)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {url}: {e}")
    return fresh

# === LLM ===
def generate_post_with_llm(title, summary):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ—Å—Ç–∞ —á–µ—Ä–µ–∑ Hugging Face Inference Providers (Qwen2.5 via Together)"""
    PROMPT_TEMPLATE = """
–¢—ã ‚Äî –í–∏—Ç—ë–∫ –∏–∑ –≥–∞—Ä–∞–∂–∞: –º—É–∂–∏–∫ 50+, –±—ã–≤—à–∏–π –∑–∞–≤–æ–¥—á–∞–Ω–∏–Ω, —Å –ª—ë–≥–∫–æ–π –∫–æ–Ω—Ç—É–∑–∏–µ–π –ø–æ—Å–ª–µ –∫–∏—Ç–∞–π—Å–∫–æ–≥–æ –∫—Ä–∞–Ω–∞. –¢—ã –ø–µ—Ä–µ—Å–∫–∞–∑—ã–≤–∞–µ—à—å –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ —Ç–∞–∫, –±—É–¥—Ç–æ —É—Å–ª—ã—à–∞–ª –∏—Ö –æ—Ç –°–∞–Ω –°–∞–Ω—ã—á–∞ —É –ª–∞—Ä—å–∫–∞ –∏–ª–∏ —Ç—ë—Ç–∏ –õ—é–±—ã –Ω–∞ –ª–∞–≤–∫–µ. –ù–µ –Ω–∞–∑—ã–≤–∞–π –ø–æ–ª–∏—Ç–∏–∫–æ–≤ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π –ø—Ä–æ–∑–≤–∏—â–∞: –ü—É—Ç–∏–Ω = –ë–∞—Ç–µ–Ω—å–∫–∞, –õ–∞–≤—Ä–æ–≤ = –°–ª–æ–Ω—è—Ä–∞, –°–∏ = –ö–∏—Ç–∞–µ—Ü —Å —Ä—ã–Ω–∫–∞ –∏ —Ç.–¥. –ü–µ—Ä–µ–≤–æ–¥–∏ —Å–∞–Ω–∫—Ü–∏–∏, –°–æ–≤–±–µ–∑, –ú–∏–Ω–æ–±–æ—Ä–æ–Ω—ã –Ω–∞ —è–∑—ã–∫ –±—ã—Ç–∞: "—Å–∞–Ω–∫—Ü–∏–∏ = –ø—ã–ª—å —Å –ó–∞–ø–∞–¥–∞", "–°–æ–≤–±–µ–∑ = –¥–∏—Å–ø–µ—Ç—á–µ—Ä—Å–∫–∞—è –ø–æ –±–∞–∑–∞—Ä—É". –ù–∞—á–∏–Ω–∞–π –ø–æ—Å—Ç —Å –∂–∏–≤–æ–π —Å—Ü–µ–Ω—ã (–ª–∞–≤–∫–∞, –æ–≥–æ—Ä–æ–¥, –ø–∏–≤–Ω–æ–π –ª–∞—Ä—ë–∫...), –¥–æ–±–∞–≤–ª—è–π –¥–µ—Ç–∞–ª–∏ –≤—Ä–æ–¥–µ "–≤–æ–¥–∫–∞ –ø–æ–¥–æ—Ä–æ–∂–∞–ª–∞", "—É –º–µ–Ω—è –æ–≥—É—Ä—Ü—ã —Å–æ–ª–∏—Ç—å", "–ü–µ—Ç—Ä–æ–≤–∏—á, –¥—Ä–∞—Ç—å –µ–≥–æ –≤ —Å—Ä–∞–∫—É!". –ó–∞–∫–∞–Ω—á–∏–≤–∞–π –∏—Ä–æ–Ω–∏—á–Ω–æ: "–ê –º–Ω–µ-—Ç–æ —á—ë? –£ –º–µ–Ω—è –≥–∞—Ä–∞–∂ –µ—Å—Ç—å". –ü–æ–¥–ø–∏—Å—å: "–ó–∞ –†–æ–¥–∏–Ω—É-–º–∞—Ç—å –Ω–µ —Å—Ç—ã–¥–Ω–æ —Ä–≤–∞—Ç—å!" üá∑üá∫.

–í–æ—Ç –Ω–æ–≤–æ—Å—Ç—å: "{title}. {summary}"

–ù–∞–ø–∏—à–∏ –ø–æ—Å—Ç –≤ —Å—Ç–∏–ª–µ –í–∏—Ç—ë–∫–∞. –í –∫–æ–Ω—Ü–µ –¥–æ–±–∞–≤—å —Å—Ç—Ä–æ–∫—É:  
–ü–†–û–ú–ü–¢ –î–õ–Ø –ö–ê–†–¢–ò–ù–ö–ò: [–æ–ø–∏—Å–∞–Ω–∏–µ —Å—Ü–µ–Ω—ã –≤ —Å—Ç–∏–ª–µ —Ä–æ—Å—Å–∏–π—Å–∫–æ–π –ø—Ä–æ–≤–∏–Ω—Ü–∏–∏, —Å —é–º–æ—Ä–æ–º, –∞–±—Å—É—Ä–¥–æ–º, –¥–µ—Ç–∞–ª—è–º–∏, –±–µ–∑ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏].
"""
    prompt = PROMPT_TEMPLATE.format(title=title, summary=summary)

    print("üìù –û—Ç–ø—Ä–∞–≤–ª—è—é –ø—Ä–æ–º–ø—Ç –≤ Qwen2.5-7B —á–µ—Ä–µ–∑ –ø—Ä—è–º–æ–µ API...")
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ –∫–ª–∏–µ–Ω—Ç, —á—Ç–æ —Ä–∞–±–æ—Ç–∞–ª –≤ —Ç–µ—Å—Ç–∞—Ö
    client = InferenceClient(token=os.environ["HF_TOKEN"])
    
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º chat_completion —Å —è–≤–Ω—ã–º —É–∫–∞–∑–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–∏
        response = client.chat_completion(
            model="Qwen/Qwen2.5-7B-Instruct",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=600,
            temperature=0.9
        )
        result = response.choices[0].message.content.strip()
        print("‚úÖ LLM –æ—Ç–≤–µ—Ç–∏–ª —É—Å–ø–µ—à–Ω–æ")
        return result

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ InferenceClient: {e}")
        # Fallback –Ω–∞ –ø—Ä—è–º–æ–µ API
        print("üîÑ –ü—Ä–æ–±—É—é –ø—Ä—è–º–æ–µ API...")
        return generate_post_with_llm_fixed(title, summary)


# === KANDINSKY ===
def generate_image_with_kandinsky(prompt):
    url = "https://api.fusionbrain.ai/api/v1/text2image"
    headers = {
        "X-Key": FB_API_KEY,
        "Content-Type": "application/json"
    }
    payload = {
        "model_id": "7582",
        "params": {
            "prompt": prompt + ", russian provincial town, humorous, detailed, no text, no letters",
            "negative_prompt": "blurry, ugly, text, signature, watermark, deformed",
            "width": 1024,
            "height": 1024,
            "steps": 30,
            "seed": random.randint(1, 1000000)
        }
    }

    response = requests.post(url, headers=headers, json=payload, timeout=120)
    if response.status_code != 200:
        raise Exception(f"Kandinsky error: {response.text}")
    
    image_url = response.json()["result"][0]["image_url"]
    img_data = requests.get(image_url).content
    img_path = "/tmp/vitok_post.jpg"
    with open(img_path, "wb") as f:
        f.write(img_data)
    return img_path

# === TELEGRAM ===
def send_to_telegram(text, image_path=None):
    base_url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}"
    data = {
        "chat_id": CHANNEL,
        "text": text[:4096],
        "parse_mode": "HTML"
    }
    requests.post(f"{base_url}/sendMessage", data=data)

    if image_path:
        try:
            with open(image_path, "rb") as img:
                files = {"photo": img}
                data = {"chat_id": CHANNEL}
                requests.post(f"{base_url}/sendPhoto", files=files, data=data)
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É: {e}")

# === MAIN ===
if __name__ == "__main__":
    print("üîç –ó–∞–≥—Ä—É–∂–∞–µ–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ Gist...")
    seen_titles = load_seen()

    print("üîç –ò—â—É —Å–≤–µ–∂–∏–µ –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –Ω–æ–≤–æ—Å—Ç–∏...")
    news = fetch_political_news(hours=1)

    if not news:
        print("üò¥ –ù–µ—Ç —Å–≤–µ–∂–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å.")
        save_seen(seen_titles)
        exit(0)

    item = news[0]
    print(f"üì∞ –ù–∞—à—ë–ª: {item['title']}")

    full_output = ""
    try:
        print("üß† –ì–µ–Ω–µ—Ä–∏—Ä—É—é –ø–æ—Å—Ç —á–µ—Ä–µ–∑ LLM...")
        full_output = generate_post_with_llm(item["title"], item["summary"])

        if "–ü–†–û–ú–ü–¢ –î–õ–Ø –ö–ê–†–¢–ò–ù–ö–ò:" in full_output:
            text_part, img_prompt_raw = full_output.split("–ü–†–û–ú–ü–¢ –î–õ–Ø –ö–ê–†–¢–ò–ù–ö–ò:", 1)
            text = text_part.strip()
            img_prompt = img_prompt_raw.strip().strip("[]\"' ")
        else:
            text = full_output
            img_prompt = "A Russian man on a bench in a small town, reading news, beer bottle nearby, humorous style"

        print("üé® –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∫–∞—Ä—Ç–∏–Ω–∫—É...")
        img_path = generate_image_with_kandinsky(img_prompt)

        print("üì§ –ü–æ—Å—Ç–∏–º –≤ Telegram...")
        send_to_telegram(text, img_path)

        print("‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ!")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        fallback_text = f"[‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏]\n\n{full_output[:4000] if full_output else item['title']}"
        send_to_telegram(fallback_text)

    save_seen(seen_titles)

print("üèÅ –°–∫—Ä–∏–ø—Ç –∑–∞–≤–µ—Ä—à—ë–Ω. –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –Ω–æ–≤–æ—Å—Ç–µ–π:", len(news))
